{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import re\n",
    "from itertools import groupby\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate like files\n",
    "\n",
    "def concat_files(path1, path2, split_char, split_position, new_file_ending, input_ext):\n",
    "    # path1 = current file path\n",
    "    # path2 = where the new file will go\n",
    "    # split_char = what to split by, ex. '_'\n",
    "    # split_position = position to split filename, ex 0\n",
    "    # new_file_ending = ending to add after the split, ex \"-merged.fa\"\n",
    "    # input_ext = file extension of input, ex = \".fasta\"\n",
    "    \n",
    "    files = fnmatch.filter(os.listdir(path1), \"*\" + input_ext)\n",
    "    \n",
    "    def split_name(fname): return fname.split(split_char)[split_position]\n",
    "    \n",
    "    for name, folder in groupby(sorted(files, key=split_name), key=split_name):\n",
    "        new_name = str(name) + new_file_ending\n",
    "        with open(os.path.join(path2, new_name), 'w') as outfile:\n",
    "            for fname in folder:\n",
    "                with open(os.path.join(path1, fname), 'r') as infile:\n",
    "                    outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/scicomp/home-pure/top8/lepto/lepto_genomes/primers\"\n",
    "merge_path = \"/scicomp/home-pure/top8/lepto/lepto_genomes/primers/merged_primers\"\n",
    "large_serovar_path = \"/scicomp/home-pure/top8/lepto/lepto_genomes/primers/large_serovar_concat/\"\n",
    "bacterio_path = \"/scicomp/home-pure/top8/lepto/lepto_genomes/primers/bacterio_serovars\"\n",
    "\n",
    "\n",
    "# concatenate forward and reverse primers that are of same species epithet\n",
    "# concat_files(path, merge_path, '_', -1, \"_concat.fna\", '.fasta')\n",
    "\n",
    "# concatenate all concat files from above to find alignments of entire genome\n",
    "# bash was used\n",
    "# for f in *_concat.fna; do cat $f >> large_serovar_concat/large_serovar_concat.fna\n",
    "\n",
    "# concatenate forward and reverse primers of same species epithet from bacterio.net\n",
    "# concat_files(bacterio_path, bacterio_path, '.', 0, \"_concat.fa\", \".fna\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find alignment and other information of each file\n",
    "# all mafft files have _mafft.txt ending\n",
    "\n",
    "def alignment(path_name, which_format):\n",
    "    # path_name = path to files\n",
    "    # which_format = merged, individual, or bacterio\n",
    "    \n",
    "    # initialize variables\n",
    "    names = []\n",
    "    alignments = []\n",
    "    sequence_num = []\n",
    "    accessions = []\n",
    "    lengths = []\n",
    "    name = ''\n",
    "    records = []\n",
    "\n",
    "    # select each file\n",
    "    for file in fnmatch.filter(os.listdir(path_name), \"*\" + '.txt'):\n",
    "        alignment = 0\n",
    "        matches = 0\n",
    "        mismatches = 0\n",
    "\n",
    "        if which_format == 'serovar':\n",
    "            # get name to process concat file\n",
    "            fasta_name_list = file.split('_')[:-2]\n",
    "            fasta_name_list = [name + \"_\" for name in fasta_name_list]\n",
    "            fasta_name = ''.join(map(str, fasta_name_list))\n",
    "\n",
    "            # use SeqIO to save info about the sequence file\n",
    "            records = list(SeqIO.parse(os.path.join(path_name, fasta_name + 'concat.fna'), \"fasta\"))\n",
    "        \n",
    "        elif which_format == 'merged':\n",
    "            # get name to process concat file\n",
    "            name = file.split('-')[0]\n",
    "            fasta_name = file.split('_')[0]\n",
    "\n",
    "            # use SeqIO to save info about the sequence file\n",
    "            records = list(SeqIO.parse(os.path.join(path_name,fasta_name), \"fasta\"))\n",
    "        \n",
    "        elif which_format == 'individual':\n",
    "            # get name to process concat file\n",
    "            fasta_name_list = file.split('_')[:-1]\n",
    "            fasta_name_list = [name + \"_\" for name in fasta_name_list]\n",
    "            fasta_name = ''.join(map(str, fasta_name_list))\n",
    "\n",
    "            # get accession number\n",
    "            acc = re.search(r'.+\\((GCF_.+)\\)_.+', file)\n",
    "            accessions.append(acc.group(1))\n",
    "            \n",
    "            # use SeqIO to save info about the sequence file\n",
    "            records = list(SeqIO.parse(os.path.join(path_name, fasta_name + 'concat.fna'), \"fasta\"))\n",
    "        \n",
    "        elif which_format == 'bacterio':\n",
    "            # get name to process concat file\n",
    "            fasta_name = file.split('_')[0]\n",
    "\n",
    "            # use SeqIO to save info about the sequence file\n",
    "            records = list(SeqIO.parse(os.path.join(path_name, fasta_name + '_concat.fa'), \"fasta\"))\n",
    "\n",
    "            # bacterio.net files are <numbers>.fna.\n",
    "            # inside files have 'Leptospira_<epithet>_...fna' and the epithet needs to be extracted\n",
    "            get_name = list(SeqIO.parse(os.path.join(path_name, fasta_name + '.fna'), 'fasta'))\n",
    "            for record in get_name:\n",
    "                split_id = record.id\n",
    "                split_id = split_id.split('_')\n",
    "                name = split_id[1]\n",
    "                accessions.append(split_id[3]) # not actually accession - used to make life easier\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        sequence_num.append(len(records)) # number of sequences\n",
    "\n",
    "        # get length of each sequence in the file\n",
    "        if which_format != 'serovar':\n",
    "            tmp_lengths = []\n",
    "            for record in records:\n",
    "                tmp_lengths.append(len(record.seq))\n",
    "\n",
    "            lengths.append(tmp_lengths)\n",
    "\n",
    "        # proccess mafft alignment files\n",
    "        with open(os.path.join(path_name, file)) as mafft_file:\n",
    "            next(mafft_file) # skip first line\n",
    "            for line in mafft_file:\n",
    "                if line.startswith(\"NZ_\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    matches += line.count(\"*\")\n",
    "                    mismatches += line.count(\".\")\n",
    "        if matches != 0:\n",
    "            alignment = (matches/(matches+mismatches))*100\n",
    "        else:\n",
    "            alignment = 0\n",
    "        names.append(name)\n",
    "        alignments.append(alignment)\n",
    "        \n",
    "    return names, alignments, sequence_num, accessions, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make alignments of merged data, each refseq file, and large_serovar data files\n",
    "merge_names, merge_alignments, merge_sequence_num, merge_acc, merge_lengths = alignment(merge_path, 'merged')\n",
    "ind_names, ind_alignments, ind_sequence_num, ind_acc, ind_lengths = alignment(path, 'individual')\n",
    "serovar_names, serovar_alignments, serovar_sequence_num, serovar_acc, serovar_lengths = alignment(large_serovar_path, 'serovar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           species  # of seq  nuc. identity\n",
      "0      abararensis         0       0.000000\n",
      "1           adleri         3      97.385621\n",
      "2     ainazelensis         1     100.000000\n",
      "3  ainlahdjerensis         1     100.000000\n",
      "4       alexanderi         6     100.000000\n"
     ]
    }
   ],
   "source": [
    "#merged data\n",
    "merged_data = {'species':merge_names, '# of seq':merge_sequence_num, 'nuc. identity':merge_alignments}\n",
    "merged = pd.DataFrame(merged_data)\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   # of seq  nuc. identity\n",
      "0       466       71.33758\n"
     ]
    }
   ],
   "source": [
    "# large serovar data\n",
    "large_serovar_data = {'# of seq':serovar_sequence_num, 'nuc. identity':serovar_alignments}\n",
    "large_serovar = pd.DataFrame(large_serovar_data)\n",
    "print(large_serovar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percent length per AE010300 (153 bp)\n",
    "def find_perc_lengths(which_lengths):\n",
    "    percent_lengths = []\n",
    "    for i in which_lengths:\n",
    "        tmp_perc_lengths = []\n",
    "        for j in i:\n",
    "            tmp_perc_lengths.append(round((j/153)*100, 2))\n",
    "            \n",
    "        percent_lengths.append(tmp_perc_lengths)\n",
    "\n",
    "    return percent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         accession  # of seq  nuc. identity length per AE010300\n",
      "0  GCF_016918735.1         0            0.0                  []\n",
      "1  GCF_004770415.1         1          100.0             [100.0]\n",
      "2  GCF_002811845.1         1          100.0             [100.0]\n",
      "3  GCF_002811985.1         1          100.0             [100.0]\n",
      "4  GCF_016918785.1         1          100.0             [100.0]\n"
     ]
    }
   ],
   "source": [
    "#ind data\n",
    "ind_percent_lengths = find_perc_lengths(ind_lengths)\n",
    "ind_data = {'accession':ind_acc, '# of seq':ind_sequence_num, 'nuc. identity':ind_alignments, 'length per AE010300':ind_percent_lengths}\n",
    "ind = pd.DataFrame(ind_data)\n",
    "print(ind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         accession  species serovar     strain\n",
      "0  GCF_004769835.1  biflexa          201601962\n",
      "1  GCF_004770315.1  biflexa          201601961\n",
      "2  GCF_004770325.1  biflexa          201601960\n",
      "3  GCF_004770345.1  biflexa          201601958\n",
      "4  GCF_004770805.1  biflexa          201601959\n"
     ]
    }
   ],
   "source": [
    "# genome_list.tsv\n",
    "df = pd.read_csv('/scicomp/home-pure/top8/lepto/lepto_genomes/genome_list.tsv', sep=\"\\t\")\n",
    "df = df[['assembly_accession', 'organism_name', 'infraspecific_name']]\n",
    "df.rename({'assembly_accession':'accession', 'organism_name':'species_org', 'infraspecific_name':'strain'}, axis=1, inplace=True)\n",
    "\n",
    "# replace strings and work on serovar data\n",
    "df['species_org'] = df['species_org'].str.replace(\"Leptospira\", \"\")\n",
    "df['strain'] = df['strain'].str.replace('strain=', '')\n",
    "df['serovar'] = df['species_org'].str.contains('serovar')\n",
    "df['serovar'] = df['serovar'].map({True: 'serovar', False: ''})\n",
    "move_serovar = df.pop('serovar')\n",
    "df.insert(2, 'serovar', move_serovar)\n",
    "\n",
    "# work on species data\n",
    "df['species'] = df['species_org'].str.split(' ').str[1]\n",
    "move_species = df.pop('species')\n",
    "df.insert(1, 'species', move_species)\n",
    "remove_species_org = df.pop('species_org')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         accession  species serovar     strain  # of seq  nuc. identity  \\\n",
      "0  GCF_004769835.1  biflexa          201601962         0            0.0   \n",
      "1  GCF_004770315.1  biflexa          201601961         0            0.0   \n",
      "2  GCF_004770325.1  biflexa          201601960         0            0.0   \n",
      "3  GCF_004770345.1  biflexa          201601958         0            0.0   \n",
      "4  GCF_004770805.1  biflexa          201601959         0            0.0   \n",
      "\n",
      "  length per AE010300  \n",
      "0                  []  \n",
      "1                  []  \n",
      "2                  []  \n",
      "3                  []  \n",
      "4                  []  \n"
     ]
    }
   ],
   "source": [
    "# merge genome_list and each acc data\n",
    "df2 = pd.merge(df, ind)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         accession  species serovar     strain # of seq nuc. identity  \\\n",
      "0  GCF_004769835.1  biflexa          201601962        0           0.0   \n",
      "1  GCF_004770315.1  biflexa          201601961        0           0.0   \n",
      "2  GCF_004770325.1  biflexa          201601960        0           0.0   \n",
      "3  GCF_004770345.1  biflexa          201601958        0           0.0   \n",
      "4  GCF_004770805.1  biflexa          201601959        0           0.0   \n",
      "\n",
      "  length per AE010300  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   0  \n",
      "4                   0  \n"
     ]
    }
   ],
   "source": [
    "# remove brackets from percent length per AE10300 column\n",
    "for c in df2.columns:\n",
    "    df2[c]= df2.apply(lambda x: str(x[c]).replace(\"[\",'').replace(']',''), axis=1)\n",
    "\n",
    "df2['length per AE010300'] = df2['length per AE010300'].replace('', 0)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send to tsv file\n",
    "df2.to_csv('genome_by_accession.tsv', sep=\"\\t\", index=False)\n",
    "merged.to_csv('genome_by_species.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros:\t 29 \n",
      "<5:\t 14 \n",
      ">10:\t 26\n"
     ]
    }
   ],
   "source": [
    "# count number of sequences found in merged data\n",
    "zeros = 0\n",
    "less_than_5 = 0 \n",
    "greater_than_10 = 0\n",
    "for i in merge_sequence_num:\n",
    "    if i == 0:\n",
    "        zeros += 1\n",
    "    elif 0 < i >= 5:\n",
    "        less_than_5 += 1\n",
    "    else:\n",
    "        greater_than_10 += 1\n",
    "\n",
    "# data to use to create bar graph in excel\n",
    "print('zeros:\\t', zeros, '\\n<5:\\t', less_than_5, '\\n>10:\\t', greater_than_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accessions where row == 'serovar'\n",
    "serovar_df = df2.copy()\n",
    "rows_to_drop = serovar_df[serovar_df['serovar'] != 'serovar'].index\n",
    "serovar_df.drop(rows_to_drop, inplace=True)\n",
    "serovar_acc = serovar_df['accession']\n",
    "serovar_acc.to_csv('serovar_accession.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# Use bash to concatenate files from tsv file above\n",
    "# while IFS= read -r file; do cat *\\(\"$file\"\\)_concat.fna >> serovar_concat.fna; done < \"../serovar_accession.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Name Clade          species\n",
      "0        Leptospira abarensis Korba et al. 2021    S1        abarensis\n",
      "1        Leptospira adleri Thibeaux et al. 2020    P1           adleri\n",
      "2     Leptospira ainazelensis Korba et al. 2021    P1     ainazelensis\n",
      "3  Leptospira ainlahdjerensis Korba et al. 2021    P1  ainlahdjerensis\n",
      "4     Leptospira alexanderi Brenner et al. 1999    P1       alexanderi\n"
     ]
    }
   ],
   "source": [
    "# use csv file of approved species from SME\n",
    "approved_species = pd.read_csv('/scicomp/home-pure/top8/lepto/lepto_genomes/approved_species.csv', sep=\",\")\n",
    "approved_species = approved_species[['Name', 'Clade']]\n",
    "approved_species.rename({'Clade':'clade'})\n",
    "# approved_species.to_csv('check_names.tsv', sep='\\t', index=False)\n",
    "approved_species['species'] = approved_species['Name'].astype(str).str.split().str[1]\n",
    "# approved_species.drop('Name', axis=1, inplace=True)\n",
    "approved_species.to_csv('check_names.tsv', sep='\\t', index=False)\n",
    "\n",
    "print(approved_species.head())\n",
    "# approved_species.groupby(['species']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          species  # of seq  nuc. identity length per AE10300\n",
      "0  ellinghausenii         0            0.0                 []\n",
      "1       johnsonii         1          100.0            [100.0]\n",
      "2        ryugenii         0            0.0                 []\n",
      "3          adleri         1          100.0            [100.0]\n",
      "4      barantonii         1          100.0            [100.0]\n"
     ]
    }
   ],
   "source": [
    "# work on bacterio.net data\n",
    "bacterio_names, bacterio_alignments, bacterio_sequence_num, bacterio_acc, bacterio_lengths = alignment(bacterio_path, 'bacterio')\n",
    "\n",
    "bacterio_perc_lengths = find_perc_lengths(bacterio_lengths)\n",
    "\n",
    "bacterio_data = {\"species\":bacterio_names, \"# of seq\":bacterio_sequence_num, \"nuc. identity\":bacterio_alignments, \"length per AE10300\":bacterio_perc_lengths}\n",
    "bacterio_df = pd.DataFrame(bacterio_data)\n",
    "bacterio_df['species'] = bacterio_df['species'].str.replace('abararensis', 'abarensis') # misspelling of word found\n",
    "print(bacterio_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           species # of seq nuc. identity length per AE10300  \\\n",
      "1        abarensis      0.0           0.0                  0   \n",
      "2           adleri      1.0         100.0             0100.0   \n",
      "3     ainazelensis      1.0         100.0             0100.0   \n",
      "4  ainlahdjerensis      1.0         100.0             0100.0   \n",
      "5       alexanderi      1.0         100.0             0100.0   \n",
      "\n",
      "                                           Name Clade  \n",
      "1        Leptospira abarensis Korba et al. 2021    S1  \n",
      "2        Leptospira adleri Thibeaux et al. 2020    P1  \n",
      "3     Leptospira ainazelensis Korba et al. 2021    P1  \n",
      "4  Leptospira ainlahdjerensis Korba et al. 2021    P1  \n",
      "5     Leptospira alexanderi Brenner et al. 1999    P1  \n"
     ]
    }
   ],
   "source": [
    "bacterio_merge = pd.merge(bacterio_df, approved_species, how=\"outer\")\n",
    "bacterio_merge = bacterio_merge.groupby(\"species\").first().reset_index()\n",
    "\n",
    "# remove brackets from percent lengths\n",
    "for c in bacterio_merge.columns:\n",
    "    bacterio_merge[c]= bacterio_merge.apply(lambda x: str(x[c]).replace(\"[\",' ').replace(']',''), axis=1)\n",
    "\n",
    "bacterio_merge['length per AE10300'] = bacterio_merge['length per AE10300'].str.replace(' ', '0')\n",
    "bacterio_merge.drop(bacterio_merge[bacterio_merge['species'] == 'Leptospira'].index, inplace=True) # found random Leptospira added\n",
    "print(bacterio_merge.head())\n",
    "\n",
    "bacterio_merge.to_csv('approved_serovars.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         accession  species serovar     strain # of seq nuc. identity  \\\n",
      "0  GCF_004769835.1  biflexa          201601962        0           0.0   \n",
      "1  GCF_004770315.1  biflexa          201601961        0           0.0   \n",
      "2  GCF_004770325.1  biflexa          201601960        0           0.0   \n",
      "3  GCF_004770345.1  biflexa          201601958        0           0.0   \n",
      "4  GCF_004770805.1  biflexa          201601959        0           0.0   \n",
      "\n",
      "  length per AE010300                                               Name Clade  \n",
      "0                   0  Leptospira biflexa (Wolbach and Binger 1914) N...    S1  \n",
      "1                   0  Leptospira biflexa (Wolbach and Binger 1914) N...    S1  \n",
      "2                   0  Leptospira biflexa (Wolbach and Binger 1914) N...    S1  \n",
      "3                   0  Leptospira biflexa (Wolbach and Binger 1914) N...    S1  \n",
      "4                   0  Leptospira biflexa (Wolbach and Binger 1914) N...    S1  \n"
     ]
    }
   ],
   "source": [
    "# merge approved_species to df2 to get clade column\n",
    "df2_clades = pd.merge(df2, approved_species, how=\"outer\")\n",
    "print(df2_clades.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           species  # of seq  nuc. identity  \\\n",
      "0      abararensis       0.0       0.000000   \n",
      "1           adleri       3.0      97.385621   \n",
      "2     ainazelensis       1.0     100.000000   \n",
      "3  ainlahdjerensis       1.0     100.000000   \n",
      "4       alexanderi       6.0     100.000000   \n",
      "\n",
      "                                           Name Clade  \n",
      "0                                           NaN   NaN  \n",
      "1        Leptospira adleri Thibeaux et al. 2020    P1  \n",
      "2     Leptospira ainazelensis Korba et al. 2021    P1  \n",
      "3  Leptospira ainlahdjerensis Korba et al. 2021    P1  \n",
      "4     Leptospira alexanderi Brenner et al. 1999    P1  \n"
     ]
    }
   ],
   "source": [
    "# add approved_species to merged to get clade column\n",
    "merged_clades = pd.merge(merged, approved_species, how=\"outer\")\n",
    "print(merged_clades.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to tsv file\n",
    "df2_clades.to_csv(\"accession_with_clade.tsv\", sep=\"\\t\", index=False)\n",
    "merged_clades.to_csv(\"species_with_clade.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea8d5fda10ea0a3bf1da741e3ec5e13ab2a5096c75ced4914e1b8d0bfa82e18e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
